{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "fine-tune-jp-bert-part02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hnishi/handson-language-models/blob/main/fine_tune_jp_bert_part02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia8cA7knqvOV"
      },
      "source": [
        "# huggingface transformers を使って日本語 BERT モデルをファインチューニングして感情分析 (with google colab) part02\n",
        "\n",
        "part01 に引き続いて、今回は、まとまったデータセットを使い、transformers の Trainer class を使いファインチューニングする方法を記載します。\n",
        "\n",
        "また、学習後の評価方法に関しても記載します。\n",
        "\n",
        "なお、今回はまとまった量 (4000 件程度) のデータを使って学習を行いますので、GPU の使用を推奨します (著者は google colab を使用して動作確認しています)。\n",
        "\n",
        "---\n",
        "\n",
        "この記事は、part02 です。\n",
        "\n",
        "すべての記事の目次は以下をご参照ください。\n",
        "\n",
        "https://github.com/hnishi/handson-language-models/blob/main/README.md\n",
        "\n",
        "## 参考\n",
        "\n",
        "- [huggingface transformers ドキュメント](https://huggingface.co/transformers/)\n",
        "- [BERT 論文](https://arxiv.org/abs/1810.04805)\n",
        "- [Fine-tuning a BERT model with transformers](https://towardsdatascience.com/fine-tuning-a-bert-model-with-transformers-c8e49c4e008b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Z_zhsNqvOb"
      },
      "source": [
        "## 必要なライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QtQP6vfqvOb"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9UCrH2nWSoE"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
        "from transformers import AdamW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yamyi7UdUiDh"
      },
      "source": [
        "## ファインチューニングのための学習データの準備\n",
        "\n",
        "株式会社リクルート 様が公開している [Japanese Realistic Textual Entailment Corpus (含意関係データセット) ](https://github.com/megagonlabs/jrte-corpus) を使わせていただきます。\n",
        "\n",
        "下記、制限があるため注意します。\n",
        "\n",
        "> リクルートは本データセットを非営利的な公共利用のために公開しています。分析・研究・その成果を発表するために必要な範囲を超えて利用すること（営利目的利用）は固く禁じます。\n",
        "\n",
        "## References\n",
        "\n",
        "1. 林部祐太．\n",
        "    知識の整理のための根拠付き自然文間含意関係コーパスの構築．\n",
        "    言語処理学会第26回年次大会論文集，pp.820-823. 2020. (NLP 2020)\n",
        "    [[PDF]](https://www.anlp.jp/proceedings/annual_meeting/2020/pdf_dir/P4-9.pdf)\n",
        "    [[Poster]](https://storage.googleapis.com/megagon-publications/nlp2020/p4-9_hayashibe_poster.pdf)\n",
        "2. Yuta Hayashibe.\n",
        "    Japanese Realistic Textual Entailment Corpus.\n",
        "    Proceedings of The 12th Language Resources and Evaluation Conference, pp.6829-6836. 2020. (LREC 2020)\n",
        "    [[PDF]](https://www.aclweb.org/anthology/2020.lrec-1.843.pdf)\n",
        "    [[bib]](https://www.aclweb.org/anthology/2020.lrec-1.843.bib)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1emHpw7UhMM",
        "outputId": "8a58482a-350f-4697-95a9-c733ca4b3af3"
      },
      "source": [
        "!curl -L -O https://raw.githubusercontent.com/megagonlabs/jrte-corpus/master/data/pn.tsv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  473k  100  473k    0     0  4465k      0 --:--:-- --:--:-- --:--:-- 4465k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48gZFLF7WQmd"
      },
      "source": [
        "# 各カラムの意味は https://github.com/megagonlabs/jrte-corpus#datapntsv を参照\n",
        "df = pd.read_csv(\"pn.tsv\", sep='\\t', header=None, \n",
        "                 names=[\"id\", \"label\", \"text\", \"judges\", \"usage\"])\n",
        "\n",
        "# ラベルを 1, 0, -1 --> 0, 1, 2 へ変換\n",
        "# Label:\t2 (Positive), 1 (Neutral), 0 (Negative)\n",
        "df[\"label\"] = df[\"label\"] + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqoe862xaW2I"
      },
      "source": [
        "### データの確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lxKArLXRWlzu",
        "outputId": "84957219-1ae8-4c52-9fc3-96d3fea76973"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>judges</th>\n",
              "      <th>usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pn17q00001</td>\n",
              "      <td>1</td>\n",
              "      <td>出張でお世話になりました。</td>\n",
              "      <td>{\"0\": 3}</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pn17q00002</td>\n",
              "      <td>1</td>\n",
              "      <td>朝食は普通でした。</td>\n",
              "      <td>{\"0\": 3}</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pn17q00003</td>\n",
              "      <td>2</td>\n",
              "      <td>また是非行きたいです。</td>\n",
              "      <td>{\"1\": 3}</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pn17q00004</td>\n",
              "      <td>2</td>\n",
              "      <td>また利用したいと思えるホテルでした。</td>\n",
              "      <td>{\"1\": 3}</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pn17q00005</td>\n",
              "      <td>2</td>\n",
              "      <td>駅から近くて便利でした。</td>\n",
              "      <td>{\"0\": 1, \"1\": 2}</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  label                text            judges usage\n",
              "0  pn17q00001      1       出張でお世話になりました。          {\"0\": 3}  test\n",
              "1  pn17q00002      1           朝食は普通でした。          {\"0\": 3}  test\n",
              "2  pn17q00003      2         また是非行きたいです。          {\"1\": 3}  test\n",
              "3  pn17q00004      2  また利用したいと思えるホテルでした。          {\"1\": 3}  test\n",
              "4  pn17q00005      2        駅から近くて便利でした。  {\"0\": 1, \"1\": 2}  test"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo7Hu1YOXhUq"
      },
      "source": [
        "### ラベルごとのデータ件数の確認\n",
        "\n",
        "全体的に、positive なラベルが多いようです。\n",
        "\n",
        "したがって、¥学習の結果 positive に極端に判定されやすいモデルとなってしまう可能性があるため注意が必要です。\n",
        "\n",
        "評価指標に accuracy ではなく、F1 score などの不均衡データに関しても正しく評価できるものを選択する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "Jnry-lq-XSVf",
        "outputId": "2c5e1e71-b46d-465d-a1d4-765eb8739c55"
      },
      "source": [
        "df.groupby([\"usage\", \"label\"]).size().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f95e4e43150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCI6orTAarJO"
      },
      "source": [
        "### カスタムデータセットに変換\n",
        "\n",
        "後述する huggingface transformers の Trainer クラスで学習を行うために、カスタムデータセットとして準備します。\n",
        "\n",
        "usage が train と dev のサンプルを学習用、test のサンプルをテスト用として分割します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ipbe3XEaofZ",
        "outputId": "51c55722-a340-4771-e991-da226903effc"
      },
      "source": [
        "df_train = df[df[\"usage\"] == (\"train\" or \"val\")]\n",
        "train_docs = df_train[\"text\"].tolist()\n",
        "train_labels = df_train[\"label\"].tolist()\n",
        "len(train_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3888"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmGs90iIrS7t",
        "outputId": "63e818c0-a748-4a35-8f6f-475583b858d2"
      },
      "source": [
        "df_test = df[df[\"usage\"] == \"test\"]\n",
        "test_docs = df_test[\"text\"].tolist()\n",
        "test_labels = df_test[\"label\"].tolist()\n",
        "len(test_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "553"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GODwxE1JxB31",
        "outputId": "3d30753c-144b-408a-96e4-232b8247931e"
      },
      "source": [
        "# GPU が利用できる場合は GPU を利用する\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euwzh2WVvLsX"
      },
      "source": [
        "model_name = \"cl-tohoku/bert-large-japanese\"\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "model = model.to(device)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn3SxlXSri_3"
      },
      "source": [
        "train_encodings = tokenizer(train_docs, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n",
        "test_encodings = tokenizer(test_docs, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyJPcPUBbCBG"
      },
      "source": [
        "import torch\n",
        "\n",
        "class JpSentiDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = JpSentiDataset(train_encodings, train_labels)\n",
        "test_dataset = JpSentiDataset(test_encodings, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plxw-na37aze"
      },
      "source": [
        "# We can set `requires_grad` to `False` for all the base model parameters in order to fine-tune only the task-specific parameters.\n",
        "# Ref: https://huggingface.co/transformers/training.html#freezing-the-encoder\n",
        "\n",
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# For more detail, see https://korenv20.medium.com/do-we-need-to-freeze-embeddings-when-fine-tuning-our-lm-c8bccf4ffeba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQkKUA7E-dkl"
      },
      "source": [
        "# To calculate additional metrics in addition to the loss, you can also define your own compute_metrics function and pass it to the trainer.\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3ly6REPhm1g"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\r\n",
        "\r\n",
        "training_args = TrainingArguments(\r\n",
        "    output_dir='./results',          # output directory\r\n",
        "    num_train_epochs=1,              # total number of training epochs\r\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\r\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\r\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\r\n",
        "    weight_decay=0.01,               # strength of weight decay\r\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.\r\n",
        "    dataloader_pin_memory=False,  # Whether you want to pin memory in data loaders or not. Will default to True\r\n",
        "    # evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\r\n",
        "    evaluation_strategy=\"steps\",\r\n",
        "    logging_steps=50,\r\n",
        "    logging_dir='./logs'\r\n",
        ")\r\n",
        "\r\n",
        "trainer = Trainer(\r\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\r\n",
        "    args=training_args,                  # training arguments, defined above\r\n",
        "    train_dataset=train_dataset,         # training dataset\r\n",
        "    eval_dataset=test_dataset,             # evaluation dataset\r\n",
        "    compute_metrics=compute_metrics  # The function that will be used to compute metrics at evaluation\r\n",
        ")\r\n",
        "\r\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL6tBjkjFcFT"
      },
      "source": [
        "# evaluation のみ実行\n",
        "trainer.evaluate(eval_dataset=test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ2OBjGE_tOk"
      },
      "source": [
        "## 評価\n",
        "\n",
        "学習の評価指標はデフォルトでは、 `runs/**CURRENT_DATETIME_HOSTNAME**` に出力されます。\n",
        "\n",
        "tensorboard での可視化が可能です。\n",
        "\n",
        "Ref: https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXEaLKoK-Lw2"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-oJJlhAtoJj"
      },
      "source": [
        "## fine tune したモデルで推論\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vik5rX9N0CSr"
      },
      "source": [
        "from transformers import pipeline\r\n",
        "\r\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=model.to(\"cpu\"), tokenizer=model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zb7fHMV0jD8"
      },
      "source": [
        "sentiment_analyzer(\"私はこの映画をみることができて、とても嬉しい。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmusByR20uwM"
      },
      "source": [
        "sentiment_analyzer(\"猫に足を噛まれて痛い。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6SLiGR0KBmD"
      },
      "source": [
        "list_text = [\n",
        "             'この人は、この世の中で、いちばんしあわせな人にちがいありません。',\n",
        "             '芝居小屋もすばらしいし、お客さんもすばらしい人たちでした。',\n",
        "             'もし中世の時代だったら、おそらく、火あぶりにされたでしょうよ。',\n",
        "             'みんなのうるさいことといったら、まるで、ハエがびんの中で、ブンブンいっているようでした。',\n",
        "             'われわれ人間が、こういうことを考えだすことができるとすれば、われわれは、地の中にうめられるまでに、もっと長生きできてもいいはずだが'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSM1vdlHKJYJ"
      },
      "source": [
        "_ = list(map(lambda x: print(f\"{x}: {sentiment_analyzer(x)}\"), list_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJxKfbkA64hP"
      },
      "source": [
        "## 学習済みモデルを保存\n",
        "\n",
        "以下では、colab から google drive に保存する場合の例を示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0JzlB465_vO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0ek_8EE6QjB"
      },
      "source": [
        "save_directory = \"/content/drive/MyDrive/Colab Notebooks/trained_models/20210313_bert_sentiment_v3\"\n",
        "\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mGL0p3wrbvs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}